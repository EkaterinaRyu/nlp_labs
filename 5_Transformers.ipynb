{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1Rlf1FnC6MxFEpGueGqKd_S863oskDQkz","authorship_tag":"ABX9TyN8ExN287sYvie98cFcu80g"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"f5ba1633956b469d86075ebffc14d3d4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3a3bb7deafec4956b6311f74ad84c871","IPY_MODEL_facf2f29d0ea4c2f9f611da5d3fa4556","IPY_MODEL_296d7607860c4a3ba3469483819730bb"],"layout":"IPY_MODEL_57ae9ce01fd94af8b218e409b0fbced1"}},"3a3bb7deafec4956b6311f74ad84c871":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_61dc0fb5d4c84dad9c3010f3e5e9f707","placeholder":"​","style":"IPY_MODEL_5fd9591ae65343e390fcb9337d8f3b88","value":"source.spm: 100%"}},"facf2f29d0ea4c2f9f611da5d3fa4556":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_18eeb5fa49574009af75c8e7051b148b","max":778395,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f7560b2af8984f01b8e3e70c40bc41e0","value":778395}},"296d7607860c4a3ba3469483819730bb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9ff1cee5ddcf4a71b3590df6c6788200","placeholder":"​","style":"IPY_MODEL_dcd1258910824d11855ab1cf729bdef3","value":" 778k/778k [00:00&lt;00:00, 3.23MB/s]"}},"57ae9ce01fd94af8b218e409b0fbced1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"61dc0fb5d4c84dad9c3010f3e5e9f707":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5fd9591ae65343e390fcb9337d8f3b88":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"18eeb5fa49574009af75c8e7051b148b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f7560b2af8984f01b8e3e70c40bc41e0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9ff1cee5ddcf4a71b3590df6c6788200":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dcd1258910824d11855ab1cf729bdef3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e3bcdd0d4ac946d7a2955accd7bfb9a4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a6d7a4bd88fd45ee98d6492d5e2589af","IPY_MODEL_c5c7445540d04e8e8dd5d8fbd4cce477","IPY_MODEL_f09c6f7457da4592865220fe26519610"],"layout":"IPY_MODEL_f4198f71f15c48e2bff189e14725f967"}},"a6d7a4bd88fd45ee98d6492d5e2589af":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1d513f6ab38149c2973cb26f89a89725","placeholder":"​","style":"IPY_MODEL_8f68c861c573434e98f2df1d436c1dd6","value":"target.spm: 100%"}},"c5c7445540d04e8e8dd5d8fbd4cce477":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b88ad15ebc9941debc4588a05b5c093a","max":802397,"min":0,"orientation":"horizontal","style":"IPY_MODEL_09a77caf99534c14bdbe8ff803821634","value":802397}},"f09c6f7457da4592865220fe26519610":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d3191220102f42deab70d50b09a7e1e8","placeholder":"​","style":"IPY_MODEL_75170d0b26074f2984d8087b913f72c0","value":" 802k/802k [00:00&lt;00:00, 4.45MB/s]"}},"f4198f71f15c48e2bff189e14725f967":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1d513f6ab38149c2973cb26f89a89725":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8f68c861c573434e98f2df1d436c1dd6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b88ad15ebc9941debc4588a05b5c093a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"09a77caf99534c14bdbe8ff803821634":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d3191220102f42deab70d50b09a7e1e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"75170d0b26074f2984d8087b913f72c0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a42965a7bc7b4a318a27cf3896a334b2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_51879994358c4b90a0b75c37b03f796e","IPY_MODEL_bfabde03e56c44f4a01e652c101f5272","IPY_MODEL_549c39e73ca842bfbd52755af54446e6"],"layout":"IPY_MODEL_c2b12dc9120440a28f501b3d4c8af228"}},"51879994358c4b90a0b75c37b03f796e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_28cff56586df4cd39e4d1d980a70d042","placeholder":"​","style":"IPY_MODEL_cae6f67708c647a0bd75917e0c9d8887","value":"vocab.json: 100%"}},"bfabde03e56c44f4a01e652c101f5272":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bf2f2343a659447389e3a3a14ee07113","max":1339166,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0240416a1c48453ea152f137b74f093c","value":1339166}},"549c39e73ca842bfbd52755af54446e6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f0377a0565724fbbaa863d8521c1e68a","placeholder":"​","style":"IPY_MODEL_d2b95cc5ee4944848d3ac540c38ec0e0","value":" 1.34M/1.34M [00:00&lt;00:00, 3.27MB/s]"}},"c2b12dc9120440a28f501b3d4c8af228":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"28cff56586df4cd39e4d1d980a70d042":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cae6f67708c647a0bd75917e0c9d8887":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bf2f2343a659447389e3a3a14ee07113":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0240416a1c48453ea152f137b74f093c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f0377a0565724fbbaa863d8521c1e68a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d2b95cc5ee4944848d3ac540c38ec0e0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b46a7b750e184559a21e67a8854ca0f8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cf9f67a00a2a4de68d90c13e40885e18","IPY_MODEL_7ed20fd7712b44d784926a9d0865cfa4","IPY_MODEL_4e1a48f784b443feb0bd414e087e0398"],"layout":"IPY_MODEL_65399df2632b49619d968ce836fa72cb"}},"cf9f67a00a2a4de68d90c13e40885e18":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6efd3308f4d34d0dbc4f64845564648c","placeholder":"​","style":"IPY_MODEL_c756e7e21ef84722865137a34ebf3939","value":"Map: 100%"}},"7ed20fd7712b44d784926a9d0865cfa4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5096a36dfc404cb3a0c86a0e80d3b8df","max":189155,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bb58c25e37e64d57aa9aabaea3a55f12","value":189155}},"4e1a48f784b443feb0bd414e087e0398":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_26e99f943124486b9539c2b23da3e651","placeholder":"​","style":"IPY_MODEL_16454c45693849f9b3c9f1a4d9b75d95","value":" 189155/189155 [01:06&lt;00:00, 2715.36 examples/s]"}},"65399df2632b49619d968ce836fa72cb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6efd3308f4d34d0dbc4f64845564648c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c756e7e21ef84722865137a34ebf3939":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5096a36dfc404cb3a0c86a0e80d3b8df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bb58c25e37e64d57aa9aabaea3a55f12":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"26e99f943124486b9539c2b23da3e651":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"16454c45693849f9b3c9f1a4d9b75d95":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"be03ddf616f1489c8b77e3faba5a3103":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6dd86badcee84534a7bc55879948bd48","IPY_MODEL_4d5fcec2ec7e4597a898847f64c138c0","IPY_MODEL_b13013af8ee14c78853c53e1a5376609"],"layout":"IPY_MODEL_1a555fc8b96a4822a522cb3fa209db73"}},"6dd86badcee84534a7bc55879948bd48":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c29d0e325d5d4bcd8ae39ced25399ef1","placeholder":"​","style":"IPY_MODEL_e524535cbae2416190fbe6beff9bbe2d","value":"Map: 100%"}},"4d5fcec2ec7e4597a898847f64c138c0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_78dc08dfcaac4b81ba7fa3cd49cb8952","max":21018,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e69c66929a914853a647ca4155aa6ad7","value":21018}},"b13013af8ee14c78853c53e1a5376609":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f913c90dcc1a4f73b4fd29bf7d1e9c20","placeholder":"​","style":"IPY_MODEL_d1c2af2354424c6a9f7697561921be2d","value":" 21018/21018 [00:07&lt;00:00, 3037.10 examples/s]"}},"1a555fc8b96a4822a522cb3fa209db73":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c29d0e325d5d4bcd8ae39ced25399ef1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e524535cbae2416190fbe6beff9bbe2d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"78dc08dfcaac4b81ba7fa3cd49cb8952":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e69c66929a914853a647ca4155aa6ad7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f913c90dcc1a4f73b4fd29bf7d1e9c20":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d1c2af2354424c6a9f7697561921be2d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"202c9abf920a4b658cdbfcb1fddfd4e0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1a781ee9042c4b84b27fa5859bac03df","IPY_MODEL_023618b106cf49d68871b6b0dfed3aeb","IPY_MODEL_1a275270635b4ebdb7d2a21b46a52e6c"],"layout":"IPY_MODEL_3670992f07bc412d871b62e1198db4f2"}},"1a781ee9042c4b84b27fa5859bac03df":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c61cdcf51c1d4d44855e165408e2030a","placeholder":"​","style":"IPY_MODEL_9525b31429f943efab110e587fd9ecac","value":"Downloading builder script: 100%"}},"023618b106cf49d68871b6b0dfed3aeb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cc3b81b039c64c709634cac6971ba379","max":8146,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b3b4ed6880d34ab7a96ce1d286465a0a","value":8146}},"1a275270635b4ebdb7d2a21b46a52e6c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9ff0e724becc4867be35d31e43e4b0ee","placeholder":"​","style":"IPY_MODEL_5c997eac9cb44ba2a98f9b2e77832a02","value":" 8.15k/8.15k [00:00&lt;00:00, 268kB/s]"}},"3670992f07bc412d871b62e1198db4f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c61cdcf51c1d4d44855e165408e2030a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9525b31429f943efab110e587fd9ecac":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cc3b81b039c64c709634cac6971ba379":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b3b4ed6880d34ab7a96ce1d286465a0a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9ff0e724becc4867be35d31e43e4b0ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c997eac9cb44ba2a98f9b2e77832a02":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","import numpy as np\n","import pandas as pd\n","import os\n","import json\n","\n","from tqdm import tqdm\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import roc_auc_score\n","from sklearn.decomposition import PCA\n","from sklearn.cluster import AgglomerativeClustering\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import BertModel, BertTokenizer, BertForSequenceClassification\n","from torch.optim import AdamW\n","from transformers import get_linear_schedule_with_warmup"],"metadata":{"id":"S9Zqdd1xKd-w","executionInfo":{"status":"ok","timestamp":1703757656077,"user_tz":-180,"elapsed":14846,"user":{"displayName":"Ekaterina Esina","userId":"08559422542032477941"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["is_cuda = False\n","\n","if is_cuda:\n","    device = torch.device(\"cuda\")\n","    print(\"GPU is available\")\n","else:\n","    device = torch.device(\"cpu\")\n","    print(\"GPU not available, CPU used\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QveEo-4mLBCe","executionInfo":{"status":"ok","timestamp":1703757660174,"user_tz":-180,"elapsed":451,"user":{"displayName":"Ekaterina Esina","userId":"08559422542032477941"}},"outputId":"195c5252-7f27-4fb7-8e0e-dd41bc1d78f7"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["GPU not available, CPU used\n"]}]},{"cell_type":"markdown","source":["##Трансформеры"],"metadata":{"id":"hWWsdS88ayt8"}},{"cell_type":"markdown","source":["####Задание 1. Изучите технологии attention и архитектуры нейронных сетей трансформеров."],"metadata":{"id":"H4QFdye7a2Ks"}},{"cell_type":"code","source":["class CustomDataset(Dataset):\n","\n","  def __init__(self, texts, targets, tokenizer, max_len=512):\n","    self.texts = texts\n","    self.targets = targets\n","    self.tokenizer = tokenizer\n","    self.max_len = max_len\n","\n","  def __len__(self):\n","    return len(self.texts)\n","\n","  def __getitem__(self, idx):\n","    print(idx)\n","    text = str(self.texts[idx])\n","    target = self.targets[idx]\n","\n","    encoding = self.tokenizer.encode_plus(\n","        text,\n","        add_special_tokens=True,\n","        max_length=self.max_len,\n","        return_token_type_ids=False,\n","        padding='max_length',\n","        return_attention_mask=True,\n","        return_tensors='pt',\n","    )\n","\n","    return {\n","      'text': text,\n","      'input_ids': encoding['input_ids'].flatten()[:512],\n","      'attention_mask': encoding['attention_mask'].flatten()[:512],\n","      'targets': torch.tensor(target, dtype=torch.long)\n","    }"],"metadata":{"id":"-eM6csALEKmN","executionInfo":{"status":"ok","timestamp":1703757679644,"user_tz":-180,"elapsed":7,"user":{"displayName":"Ekaterina Esina","userId":"08559422542032477941"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["class BertClassifier:\n","    def __init__(self, model_path, tokenizer_path, n_classes=2, epochs=1, model_save_path='/content/bert.pt'):\n","        self.model = BertForSequenceClassification.from_pretrained(model_path)\n","        self.tokenizer = BertTokenizer.from_pretrained(tokenizer_path)\n","        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","        self.model_save_path=model_save_path\n","        self.max_len = 512\n","        self.epochs = epochs\n","        self.out_features = self.model.bert.encoder.layer[1].output.dense.out_features\n","        self.model.classifier = torch.nn.Linear(self.out_features, n_classes)\n","        self.model.to(self.device)\n","\n","    def preparation(self, X_train, y_train, X_valid, y_valid):\n","        # create datasets\n","        self.train_set = CustomDataset(X_train, y_train, self.tokenizer)\n","        self.valid_set = CustomDataset(X_valid, y_valid, self.tokenizer)\n","\n","        # create data loaders\n","        self.train_loader = DataLoader(self.train_set, batch_size=2, shuffle=True)\n","        self.valid_loader = DataLoader(self.valid_set, batch_size=2, shuffle=True)\n","\n","        # helpers initialization\n","        self.optimizer = AdamW(self.model.parameters(), lr=2e-5)\n","        self.scheduler = get_linear_schedule_with_warmup(\n","                self.optimizer,\n","                num_warmup_steps=0,\n","                num_training_steps=len(self.train_loader) * self.epochs\n","            )\n","        self.loss_fn = torch.nn.CrossEntropyLoss().to(self.device)\n","\n","    def eval(self):\n","        self.model = self.model.eval()\n","        losses = []\n","        correct_predictions = 0\n","\n","        with torch.no_grad():\n","            for data in self.valid_loader:\n","                input_ids = data[\"input_ids\"].to(self.device)\n","                attention_mask = data[\"attention_mask\"].to(self.device)\n","                targets = data[\"targets\"].to(self.device)\n","\n","                outputs = self.model(\n","                    input_ids=input_ids,\n","                    attention_mask=attention_mask\n","                    )\n","\n","                preds = torch.argmax(outputs.logits, dim=1)\n","                loss = self.loss_fn(outputs.logits, targets)\n","                correct_predictions += torch.sum(preds == targets)\n","                losses.append(loss.item())\n","\n","        val_acc = correct_predictions.double() / len(self.valid_set)\n","        val_loss = np.mean(losses)\n","        return val_acc, val_loss\n","\n","    def fit(self):\n","        self.model = self.model.train()\n","        losses = []\n","        correct_predictions = 0\n","\n","        for data in tqdm(self.train_loader):\n","            input_ids = data[\"input_ids\"].to(self.device)\n","            attention_mask = data[\"attention_mask\"].to(self.device)\n","            targets = data[\"targets\"].to(self.device)\n","\n","            outputs = self.model(\n","                input_ids=input_ids,\n","                attention_mask=attention_mask\n","                )\n","\n","            preds = torch.argmax(outputs.logits, dim=1)\n","            loss = self.loss_fn(outputs.logits, targets)\n","\n","            correct_predictions += torch.sum(preds == targets)\n","\n","            losses.append(loss.item())\n","\n","            loss.backward()\n","            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n","            self.optimizer.step()\n","            self.scheduler.step()\n","            self.optimizer.zero_grad()\n","\n","        train_acc = correct_predictions.double() / len(self.train_set)\n","        train_loss = np.mean(losses)\n","        return train_acc, train_loss\n","\n","    def predict(self, text):\n","        encoding = self.tokenizer.encode_plus(\n","            text,\n","            add_special_tokens=True,\n","            max_length=self.max_len,\n","            return_token_type_ids=False,\n","            truncation=True,\n","            padding='max_length',\n","            return_attention_mask=True,\n","            return_tensors='pt',\n","        )\n","\n","        out = {\n","            'text': text,\n","            'input_ids': encoding['input_ids'].flatten(),\n","            'attention_mask': encoding['attention_mask'].flatten()\n","        }\n","\n","        input_ids = out[\"input_ids\"].to(self.device)\n","        attention_mask = out[\"attention_mask\"].to(self.device)\n","\n","        outputs = self.model(\n","            input_ids=input_ids.unsqueeze(0),\n","            attention_mask=attention_mask.unsqueeze(0)\n","        )\n","\n","        prediction = torch.argmax(outputs.logits, dim=1).cpu().numpy()[0]\n","\n","        return prediction\n","\n","    def train(self):\n","        best_accuracy = 0\n","        for epoch in range(self.epochs):\n","            print(f'Epoch {epoch + 1}/{self.epochs}')\n","            train_acc, train_loss = self.fit()\n","            print(f'Train loss {train_loss} accuracy {train_acc}')\n","\n","            val_acc, val_loss = self.eval()\n","            print(f'Val loss {val_loss} accuracy {val_acc}')\n","            print('-' * 10)\n","\n","            if val_acc > best_accuracy:\n","                torch.save(self.model, self.model_save_path)\n","                best_accuracy = val_acc\n","\n","        self.model = torch.load(self.model_save_path)\n","\n"],"metadata":{"id":"EP1ou8ibLgii","executionInfo":{"status":"ok","timestamp":1703757681118,"user_tz":-180,"elapsed":12,"user":{"displayName":"Ekaterina Esina","userId":"08559422542032477941"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"1FXGfIPE5tov"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####Задание 2. Примените один из трансформеров, например BERT к задаче классификации отзывов клиентов. Сравните полученные результаты с классическими методами машинного обучения, с RNN. Сделайте выводы."],"metadata":{"id":"bhrxpflVa32L"}},{"cell_type":"code","source":["sample_positive = pd.read_json('/content/drive/MyDrive/Colab Notebooks/тексты/предыдущее/sample_positive.json')\n","sample_negative = pd.read_json('/content/drive/MyDrive/Colab Notebooks/тексты/предыдущее/sample_negative.json')\n","\n","sample_positive['grade'] = 1\n","sample_negative['grade'] = 0\n","\n","dataframe = pd.concat([sample_positive[['text', 'grade']], sample_negative[['text', 'grade']]], ignore_index=True)\n","dataframe = dataframe.drop(3436, axis=0).reset_index().drop('index', axis=1)"],"metadata":{"id":"7c6qKywmrod_","executionInfo":{"status":"ok","timestamp":1703757687365,"user_tz":-180,"elapsed":3483,"user":{"displayName":"Ekaterina Esina","userId":"08559422542032477941"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["X_train, X_test, y_train, y_test = train_test_split(dataframe['text'].tolist(), dataframe['grade'].tolist(), train_size=0.8, random_state=42)\n","\n","print(len(X_train), len(y_train))\n","print(len(X_test), len(y_test))\n","\n","help = BertClassifier('cointegrated/rubert-tiny', 'cointegrated/rubert-tiny', epochs=3)\n","\n","help.preparation(X_train, y_train, X_test, y_test)\n","help.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":581},"id":"tUMZIwtiKRSK","executionInfo":{"status":"error","timestamp":1703757728130,"user_tz":-180,"elapsed":5016,"user":{"displayName":"Ekaterina Esina","userId":"08559422542032477941"}},"outputId":"bd10076e-6845-4cca-dad0-421be1d0a8db"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["1986\n","1639\n"]},{"output_type":"stream","name":"stderr","text":["\r  1%|          | 17/2083 [00:18<29:13,  1.18it/s]"]},{"output_type":"stream","name":"stdout","text":["3000\n","2077\n"]},{"output_type":"stream","name":"stderr","text":["\r  1%|          | 18/2083 [00:19<32:39,  1.05it/s]"]},{"output_type":"stream","name":"stdout","text":["2341\n","2019\n"]},{"output_type":"stream","name":"stderr","text":["\r  1%|          | 19/2083 [00:20<34:30,  1.00s/it]"]},{"output_type":"stream","name":"stdout","text":["624\n","4105\n"]},{"output_type":"stream","name":"stderr","text":["\r  1%|          | 20/2083 [00:21<35:35,  1.03s/it]"]},{"output_type":"stream","name":"stdout","text":["1820\n","3506\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 21/2083 [00:23<37:45,  1.10s/it]\n"]},{"output_type":"stream","name":"stdout","text":["2444\n","1120\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-b686183023b4>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mhelp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreparation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mhelp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-6-83e4b907e30a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch {epoch + 1}/{self.epochs}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Train loss {train_loss} accuracy {train_acc}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-83e4b907e30a>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"targets\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             outputs = self.model(\n\u001b[0m\u001b[1;32m     67\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1562\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1564\u001b[0;31m         outputs = self.bert(\n\u001b[0m\u001b[1;32m   1565\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1566\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1011\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m         )\n\u001b[0;32m-> 1013\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1014\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    605\u001b[0m                 )\n\u001b[1;32m    606\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    608\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    537\u001b[0m             \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcross_attn_present_key_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m         layer_output = apply_chunking_to_forward(\n\u001b[0m\u001b[1;32m    540\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pytorch_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["dataframe"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"39P7pIne4D8D","executionInfo":{"status":"ok","timestamp":1703757763660,"user_tz":-180,"elapsed":10,"user":{"displayName":"Ekaterina Esina","userId":"08559422542032477941"}},"outputId":"62508708-e6d9-496d-cdb9-3696899b523e"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                   text  grade\n","0     ВАЖНО! У кого низкий фпс открываем параметры з...      1\n","1     Луга - Пинаешь живой пень. Бегаешь за оленем. ...      1\n","2     Какими бы не были сильными боги, от срубленног...      1\n","3     Игра весит 1Гб но в ней контента больше чем в ...      1\n","4     Самая грустная история Вальхейма.Я перевозил м...      1\n","...                                                 ...    ...\n","5202                                в соло будет тяжело      0\n","5203                        мб хватит на бали чилить???      0\n","5204                                              ГОВНО      0\n","5205                 За год толком ни чего не добавили.      0\n","5206  контента 0.игра вышла в еврале 21-го года. с т...      0\n","\n","[5207 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-889564da-8e7e-4d0d-aef5-d8ca536be741\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>grade</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ВАЖНО! У кого низкий фпс открываем параметры з...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Луга - Пинаешь живой пень. Бегаешь за оленем. ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Какими бы не были сильными боги, от срубленног...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Игра весит 1Гб но в ней контента больше чем в ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Самая грустная история Вальхейма.Я перевозил м...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>5202</th>\n","      <td>в соло будет тяжело</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5203</th>\n","      <td>мб хватит на бали чилить???</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5204</th>\n","      <td>ГОВНО</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5205</th>\n","      <td>За год толком ни чего не добавили.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5206</th>\n","      <td>контента 0.игра вышла в еврале 21-го года. с т...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5207 rows × 2 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-889564da-8e7e-4d0d-aef5-d8ca536be741')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-889564da-8e7e-4d0d-aef5-d8ca536be741 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-889564da-8e7e-4d0d-aef5-d8ca536be741');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-e8ea96fc-d995-4cfd-8467-2c1c6eb5ac79\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e8ea96fc-d995-4cfd-8467-2c1c6eb5ac79')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-e8ea96fc-d995-4cfd-8467-2c1c6eb5ac79 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["# torch.save(help.model, f'/content/drive/MyDrive/Colab Notebooks/тексты/5_Transformers/content/tiny-bert-3.pt')"],"metadata":{"id":"GJSoyPvII6bj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["help.predict('кал зеленого гоблина который бьет меня дубиной, приятного мало, конечно')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i6GYzPHFwxKj","executionInfo":{"status":"ok","timestamp":1702106540666,"user_tz":-180,"elapsed":267,"user":{"displayName":"Ekaterina Esina","userId":"08559422542032477941"}},"outputId":"d7395c53-1e94-4520-a64d-2d809b0b08ad"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["help.predict('самая лучшая игра')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t5GOz8KadMOn","executionInfo":{"status":"ok","timestamp":1702106637611,"user_tz":-180,"elapsed":354,"user":{"displayName":"Ekaterina Esina","userId":"08559422542032477941"}},"outputId":"80a38334-239f-439b-e9b5-2deff7294845"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","source":["####Задание 3. Примените один из трансформеров, например BERT, к задаче генерации англоязычного и русскоязычного текстов. Сравните результаты с LSTM. Сделайте выводы.\n"],"metadata":{"id":"-ITYI2gYa64i"}},{"cell_type":"code","source":["from transformers import pipeline\n","\n","generator = pipeline('text-generation', model='gpt2')\n","generator(\"Hello, I'm a language model,\", max_length=30, num_return_sequences=5)"],"metadata":{"id":"UQ5CCJOHbNwu","executionInfo":{"status":"ok","timestamp":1702078453889,"user_tz":-180,"elapsed":8106,"user":{"displayName":"Ekaterina Esina","userId":"08559422542032477941"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a75c9a50-42bc-4008-c8ed-f2d05cdb3e26"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]},{"output_type":"execute_result","data":{"text/plain":["[{'generated_text': 'Hello, I\\'m a language model, not a science fiction character.\"\\n\\nIn its quest to explain human language, MIT researchers used brain scans and'},\n"," {'generated_text': \"Hello, I'm a language model, not an artificial model. One that's not based on any sort of real data or any sort of abstract idea\"},\n"," {'generated_text': \"Hello, I'm a language model, I teach a language model to my students. And there really isn't a single one of those types. I\"},\n"," {'generated_text': \"Hello, I'm a language model, a language model that is very easy to learn with. And I also think it shows us the way that languages\"},\n"," {'generated_text': 'Hello, I\\'m a language model, but I\\'m also a computer science student in a university department with a PhD in science.\"\\n\\n\"What'}]"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["generator = pipeline('text-generation', model='sberbank-ai/rugpt3large_based_on_gpt2')\n","generator(\"Привет, помоги мне пожалуйста все забыть\", max_length=30)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BDEaGaTGvJZK","executionInfo":{"status":"ok","timestamp":1702078538482,"user_tz":-180,"elapsed":35099,"user":{"displayName":"Ekaterina Esina","userId":"08559422542032477941"}},"outputId":"06d8e014-cb14-4d6d-fc47-ec8fdc33a0f2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'generated_text': 'Привет, помоги мне пожалуйста все забыть.\\nПопробуй с ним поговорить, может он не хочет с тобой общаться, а ты ему нравишься.'}]"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["#####Training"],"metadata":{"id":"gyuPmY7MvD5b"}},{"cell_type":"code","source":["from transformers import GPT2Tokenizer, GPT2LMHeadModel # GPT2Model\n","\n","# model = GPT2Model.from_pretrained('gpt2')\n","\n","tokenizer = GPT2Tokenizer.from_pretrained('sberbank-ai/rugpt3large_based_on_gpt2')\n","model = GPT2LMHeadModel.from_pretrained('sberbank-ai/rugpt3large_based_on_gpt2')\n","\n","# text = \"you know i can't help you, but here are some options for you\"\n","text = \"а ты говоришь по-русски?\"\n","encoded_input = tokenizer(text, return_tensors='pt')\n","output = model(**encoded_input)"],"metadata":{"id":"gu--opNNTuhi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import TextDataset, DataCollatorForLanguageModeling\n","\n","train_dataset = TextDataset(tokenizer=tokenizer,\n","                            file_path='/content/drive/MyDrive/Colab Notebooks/тексты/dostoevsky.txt',\n","                            block_size=64)\n","\n","data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CjogqyNfbwyw","executionInfo":{"status":"ok","timestamp":1702057361758,"user_tz":-180,"elapsed":5781,"user":{"displayName":"Ekaterina Esina","userId":"08559422542032477941"}},"outputId":"d1800b7d-a52d-4160-e727-849280669461"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["# pip install accelerate -U"],"metadata":{"id":"tZhVf4ppflRu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import Trainer, TrainingArguments\n","\n","training_args = TrainingArguments(\n","    output_dir=\"/content/drive/MyDrive/Colab Notebooks/тексты/5_Transformers/gpt\",\n","    overwrite_output_dir=True, #overwrite the content of the output directory\n","    num_train_epochs=2, # number of training epochs\n","    per_device_train_batch_size=32, # batch size for training\n","    per_device_eval_batch_size=32,  # batch size for evaluation\n","    warmup_steps=0,# number of warmup steps for learning rate scheduler\n","    gradient_accumulation_steps=0, # to make \"virtual\" batch size larger\n","    )\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    data_collator=data_collator,\n","    train_dataset=train_dataset,\n","    optimizers = (torch.optim.AdamW(model.parameters(),lr=1e-5),None) # Optimizer and lr scheduler\n",")"],"metadata":{"id":"sFpNE6e8bwjZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# trainer.train()"],"metadata":{"id":"0hXzS9K7bwdN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"EBjsYVumbwSh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# generated_text = model.generate(\n","#     input_ids=encoded_input['input_ids'],\n","#     max_length=100,\n","#     temperature=1.2,\n","#     do_sample=True,\n","#     top_k=3,\n","#     top_p=0.95\n","# )\n","# print(f\"дано: {text}\")\n","# # print(generated_text)\n","\n","# prediction = tokenizer.decode(generated_text[0])\n","# print(prediction)"],"metadata":{"id":"9B4880DebMxI","executionInfo":{"status":"ok","timestamp":1702063465128,"user_tz":-180,"elapsed":32879,"user":{"displayName":"Ekaterina Esina","userId":"08559422542032477941"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"5e56814e-d2ce-442a-caac-043d4908575d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["дано: а ты говоришь по-русски?\n","а ты говоришь по-русски?\n","— Да.\n","— А что?\n","— А то, что у тебя в руках — не книга. Это не учебник.\n","\n","— Ну и что?\n","— А то, что я не хочу читать эту гадость. И не буду.\n","\n","— Почему?\n","— Потому что это — мерзость.\n","\n","— Почему мерзость?\n","— Потому что это — мерзость.<s>\n","Оригинал взят у в postВ Москве\n"]}]},{"cell_type":"code","source":["# text = \"анна не могла перестать трястись\"\n","# encoded_input = tokenizer(text, return_tensors='pt')\n","# output = model(**encoded_input)\n","\n","# generated_text = model.generate(\n","#     input_ids=encoded_input['input_ids'],\n","#     max_length=100,\n","#     temperature=1.2,\n","#     do_sample=True,\n","#     top_k=3,\n","#     top_p=0.95\n","# )\n","# print(f\"дано: {text}\")\n","# # print(generated_text)\n","\n","# prediction = tokenizer.decode(generated_text[0])\n","# print(prediction)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"axtui2-ug8kV","executionInfo":{"status":"ok","timestamp":1702063590744,"user_tz":-180,"elapsed":55003,"user":{"displayName":"Ekaterina Esina","userId":"08559422542032477941"}},"outputId":"c67be2b4-c832-44e4-ff3c-2dc1aba3d6ee"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["дано: анна не могла перестать трястись\n","анна не могла перестать трястись от страха и не могла понять, что происходит.\n","\n","– Что случилось? – спросила она, когда наконец поняла, что происходит.\n","\n","– Не знаю… Я не знаю, что происходит.\n","\n","– Я не могу понять… Я не могу понять, почему… – Она снова замолчала и уставилась на свои руки.\n","\n","– Я не понимаю… – снова повторила она.\n","\n","– Что происходит? – повторила\n"]}]},{"cell_type":"code","source":["# text = \"анна не могла перестать трястись\"\n","# encoded_input = tokenizer(text, return_tensors='pt')\n","# output = model(**encoded_input)\n","\n","# generated_text = model.generate(\n","#     input_ids=encoded_input['input_ids'],\n","#     max_length=500,\n","#     temperature=1.8,\n","#     do_sample=True,\n","#     top_k=30,\n","#     top_p=0.95\n","# )\n","# print(f\"дано: {text}\")\n","# # print(generated_text)\n","\n","# prediction = tokenizer.decode(generated_text[0])\n","# print(prediction)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-3Q4ClsQ5PGB","executionInfo":{"status":"ok","timestamp":1702064513789,"user_tz":-180,"elapsed":208454,"user":{"displayName":"Ekaterina Esina","userId":"08559422542032477941"}},"outputId":"2042fc92-52bf-4e05-a819-0cf1cfdcdcb8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["дано: анна не могла перестать трястись\n","анна не могла перестать трястись и в изнеможении падать вниз головой на землю. Ей не хотелось плакать или жаловаться, потому что больше плакать не осталось ни слез, ни слов. Ее глаза смотрели куда-то сквозь нее, в какой-то другой миг она могла даже сказать — никуда, ибо была в полном одиночестве. Когда боль от падения постепенно усилилась, боль, пронзавшая все мышцы, стала такой острой (это была всего только жалящая боль), что от желания закричать или закричать громко, без всяких предварительных приготовлений, ее спасал инстинкт самосохранения. И в тот же момент это чувство подсказало ей еще больше, еще больше о многом предупредить и что было сил остановить свои действия: не падать вниз (или даже наоборот — упасть не так, как упали), а лететь высоко-высоко к своему дому, к отцу, к сестре (хотя и это ей было не под силу: ноги все подкашивались, каждая косточка во всем теле ныла), — к сестре! И только одна единственная мысль стучилась в нее — «Я вернусь».. \n","\n","Глава 8. Сознание\n","\n","Сперва его просто вырвала странная волна жара; она была такой сильной и острой, что его тело в момент показалось ему пылающим в костре, а его мозг в который уж раз взорвался болью с головой — в один большой пульсирующий орган в горле! С этого момента тело уже не принадлежало разуму его бывшего хозяина – тело целиком и полностью находилось под огнем. \n","\n","— О, черт возьми! Что там происходит?! Кто тебя сотворил? \n","\n","— Хватка у тебя железная, мой Лорд?! Откуда в тебе вообще взялись силы! Где твои инстинкты, твой разум?! — с неподдельным ужасом спросил он, когда все его органы начали в бешенстве и истерии биться, изрыгая жгучий яд; их движения казались стремительными и порывистыми и все равно ничего было в них не понять. — Кто ты есть?!! Кто твои хозяева или… Кто ты такое?! \n","\n","— Заткнись, парень, ты уже труп, вот и все дела, — злобно и с отвращением отозвался он, с большим трудом ворочаясь при попытках освободиться, и ему стало больно при этом даже кричать (конечно, если это все же он; и если на него и нападало желание крикнуть, то в то время как у него и был этот момент свободы и силы!). Все что оставалось, это просто лежать в забытьи; ему стало\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"3TXCNe-j9ux8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# en_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n","# en_model = GPT2LMHeadModel.from_pretrained('gpt2')\n","\n","# text = \"help me, i can't stop\"\n","# encoded_input = en_tokenizer(text, return_tensors='pt')\n","# output = en_model(**encoded_input)\n","\n","# generated_text = en_model.generate(\n","#     input_ids=encoded_input['input_ids'],\n","#     max_length=300,\n","#     temperature=1.8,\n","#     do_sample=True,\n","#     top_k=30,\n","#     top_p=0.95\n","# )\n","# print(f\"дано: {text}\\n\")\n","# # print(generated_text)\n","\n","# prediction = en_tokenizer.decode(generated_text[0])\n","# print(prediction)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ho_yoqrv9us6","executionInfo":{"status":"ok","timestamp":1702064879644,"user_tz":-180,"elapsed":37448,"user":{"displayName":"Ekaterina Esina","userId":"08559422542032477941"}},"outputId":"b6f48a47-bf9b-484e-a5c1-a68545942742"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["дано: help me, i can't stop\n","\n","help me, i can't stop smiling at you. Please let me sleep at your hotel room tomorrow for two days. I'm looking forward to you knowing me too good. Thanks!\"\n","\n","\"Hi!\"\n","\n","\"No thankless thanks for letting you sleep!\" shouted Neeb.\n","\n","They started laughing a little but Nelly looked a little disappointed at what she saw from his reaction too\n","\n","\"No… neeb, what was the most difficult step to taking, your new boyfriend?\" asked Yap.\n","\n","Nyey sighed\n","\n","\"Yeah, the most impossible steps! Oh my..\"\n","\n","The couple exchanged several glances with one another who smiled at all those smiling but no one saw or said anything about Nelly. He just looked sad and embarrassed\n","\n","\"Uh… uh.. I wonder...\" said Niey. He was happy now and looked satisfied at the happy expression on the woman and even laughed his heart off too. Nynifu took out two big muffs from a metal box from Neeb's hand like that before throwing some money into his pocket and started working out as Yap called by talking the first question he heard the following. It would definitely pay big attention to his words but not when he said they'd done.\n","\n","Yap didn't think Yap would take a single minute to figure that a man in a big black mask could stand at the front gate just trying to get a quick word out\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"FwJxPq3F9ujI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","import torch\n","from transformers import GPT2LMHeadModel, GPT2Tokenizer\n","\n","model_name = 'gpt2'  # or 'gpt2-medium', 'gpt2-large', 'gpt2-xl' for larger models\n","model = GPT2LMHeadModel.from_pretrained(model_name)\n","tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n","\n","model.eval()\n","\n","input_text = \"Your input text goes here\"\n","input_ids = tokenizer.encode(input_text, return_tensors='pt')\n","\n","output = model.generate(input_ids, max_length=100, num_return_sequences=1)\n","generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n","\n","print(generated_text)\n","\n","\"\"\""],"metadata":{"id":"hk-NFwJvT0vF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"LkUg_ZXynPD7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####Задание 4. Примените один из трансформеров, например BERT, к задаче машинного перевода.\n"],"metadata":{"id":"3REuS_cna9E3"}},{"cell_type":"code","source":["from transformers import pipeline\n","\n","translator = pipeline(\"translation\", model=\"t5-small\",\n","                      src_lang='en', tgt_lang='de')\n","translator(\"i really need help\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ipxx26OAi_ub","executionInfo":{"status":"ok","timestamp":1702078435894,"user_tz":-180,"elapsed":1952,"user":{"displayName":"Ekaterina Esina","userId":"08559422542032477941"}},"outputId":"6b6617d9-a8f4-4341-c629-32accff719b1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'translation_text': 'Ich brauche wirklich Hilfe'}]"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["#####Automated training loop"],"metadata":{"id":"txb0U28IhjzB"}},{"cell_type":"code","source":["pip install sentencepiece"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VYIlt8QZBnoH","executionInfo":{"status":"ok","timestamp":1702066002330,"user_tz":-180,"elapsed":6768,"user":{"displayName":"Ekaterina Esina","userId":"08559422542032477941"}},"outputId":"df348dbd-81fc-45b8-a333-3d09c9960fc9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n"]}]},{"cell_type":"code","source":["from transformers import pipeline\n","\n","model_checkpoint = \"Helsinki-NLP/opus-mt-en-fr\"\n","translator = pipeline(\"translation\", model=model_checkpoint)\n","translator(\"Default to expanded threads\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":165,"referenced_widgets":["f5ba1633956b469d86075ebffc14d3d4","3a3bb7deafec4956b6311f74ad84c871","facf2f29d0ea4c2f9f611da5d3fa4556","296d7607860c4a3ba3469483819730bb","57ae9ce01fd94af8b218e409b0fbced1","61dc0fb5d4c84dad9c3010f3e5e9f707","5fd9591ae65343e390fcb9337d8f3b88","18eeb5fa49574009af75c8e7051b148b","f7560b2af8984f01b8e3e70c40bc41e0","9ff1cee5ddcf4a71b3590df6c6788200","dcd1258910824d11855ab1cf729bdef3","e3bcdd0d4ac946d7a2955accd7bfb9a4","a6d7a4bd88fd45ee98d6492d5e2589af","c5c7445540d04e8e8dd5d8fbd4cce477","f09c6f7457da4592865220fe26519610","f4198f71f15c48e2bff189e14725f967","1d513f6ab38149c2973cb26f89a89725","8f68c861c573434e98f2df1d436c1dd6","b88ad15ebc9941debc4588a05b5c093a","09a77caf99534c14bdbe8ff803821634","d3191220102f42deab70d50b09a7e1e8","75170d0b26074f2984d8087b913f72c0","a42965a7bc7b4a318a27cf3896a334b2","51879994358c4b90a0b75c37b03f796e","bfabde03e56c44f4a01e652c101f5272","549c39e73ca842bfbd52755af54446e6","c2b12dc9120440a28f501b3d4c8af228","28cff56586df4cd39e4d1d980a70d042","cae6f67708c647a0bd75917e0c9d8887","bf2f2343a659447389e3a3a14ee07113","0240416a1c48453ea152f137b74f093c","f0377a0565724fbbaa863d8521c1e68a","d2b95cc5ee4944848d3ac540c38ec0e0"]},"id":"k0PKcxQOUyHo","executionInfo":{"status":"ok","timestamp":1702066028879,"user_tz":-180,"elapsed":23916,"user":{"displayName":"Ekaterina Esina","userId":"08559422542032477941"}},"outputId":"703d9eac-bcf5-4e17-d3ad-dd1bb0c4a981"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["source.spm:   0%|          | 0.00/778k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5ba1633956b469d86075ebffc14d3d4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["target.spm:   0%|          | 0.00/802k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3bcdd0d4ac946d7a2955accd7bfb9a4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.json:   0%|          | 0.00/1.34M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a42965a7bc7b4a318a27cf3896a334b2"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/models/marian/tokenization_marian.py:197: UserWarning: Recommended: pip install sacremoses.\n","  warnings.warn(\"Recommended: pip install sacremoses.\")\n"]},{"output_type":"execute_result","data":{"text/plain":["[{'translation_text': 'Par défaut pour les threads élargis'}]"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["pip install datasets"],"metadata":{"id":"NdtrbF_iBVxe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pip install sacrebleu"],"metadata":{"id":"WJJxFT_jd87S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pip install evaluate"],"metadata":{"id":"VLuok4xseiVI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from datasets import load_dataset\n","\n","raw_dataset = load_dataset('kde4', lang1='en', lang2='fr')\n","split_datasets = raw_dataset['train'].train_test_split(train_size=0.9, seed=20)\n","split_datasets['validation'] = split_datasets.pop('test')"],"metadata":{"id":"7c0iMqxzFEac"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["split_datasets[\"train\"][1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wv8AwvPKGVYD","executionInfo":{"status":"ok","timestamp":1702067194581,"user_tz":-180,"elapsed":767,"user":{"displayName":"Ekaterina Esina","userId":"08559422542032477941"}},"outputId":"001c68bf-bce8-4b0e-ab46-cbc460014c0e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'id': '152754',\n"," 'translation': {'en': 'Default to expanded threads',\n","  'fr': 'Par défaut, développer les fils de discussion'}}"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq\n","\n","model_checkpoint = \"Helsinki-NLP/opus-mt-en-fr\"\n","tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, return_tensors=\"pt\")\n","model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n","\n","data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b0LF6q2MGVUt","executionInfo":{"status":"ok","timestamp":1702069698140,"user_tz":-180,"elapsed":10513,"user":{"displayName":"Ekaterina Esina","userId":"08559422542032477941"}},"outputId":"f8f3cf75-a630-402d-cf72-034573f17687"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/models/marian/tokenization_marian.py:197: UserWarning: Recommended: pip install sacremoses.\n","  warnings.warn(\"Recommended: pip install sacremoses.\")\n"]}]},{"cell_type":"code","source":["max_length = 128\n","\n","def preprocess_function(examples):\n","    inputs = [ex[\"en\"] for ex in examples[\"translation\"]]\n","    targets = [ex[\"fr\"] for ex in examples[\"translation\"]]\n","    model_inputs = tokenizer(inputs, text_target=targets,\n","                             max_length=max_length, truncation=True)\n","    return model_inputs\n","\n","tokenized_datasets = split_datasets.map(\n","    preprocess_function,\n","    batched=True,\n","    remove_columns=split_datasets[\"train\"].column_names,\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["b46a7b750e184559a21e67a8854ca0f8","cf9f67a00a2a4de68d90c13e40885e18","7ed20fd7712b44d784926a9d0865cfa4","4e1a48f784b443feb0bd414e087e0398","65399df2632b49619d968ce836fa72cb","6efd3308f4d34d0dbc4f64845564648c","c756e7e21ef84722865137a34ebf3939","5096a36dfc404cb3a0c86a0e80d3b8df","bb58c25e37e64d57aa9aabaea3a55f12","26e99f943124486b9539c2b23da3e651","16454c45693849f9b3c9f1a4d9b75d95","be03ddf616f1489c8b77e3faba5a3103","6dd86badcee84534a7bc55879948bd48","4d5fcec2ec7e4597a898847f64c138c0","b13013af8ee14c78853c53e1a5376609","1a555fc8b96a4822a522cb3fa209db73","c29d0e325d5d4bcd8ae39ced25399ef1","e524535cbae2416190fbe6beff9bbe2d","78dc08dfcaac4b81ba7fa3cd49cb8952","e69c66929a914853a647ca4155aa6ad7","f913c90dcc1a4f73b4fd29bf7d1e9c20","d1c2af2354424c6a9f7697561921be2d"]},"id":"2CoyLoNKGVPM","executionInfo":{"status":"ok","timestamp":1702073787085,"user_tz":-180,"elapsed":77886,"user":{"displayName":"Ekaterina Esina","userId":"08559422542032477941"}},"outputId":"07a53d6c-feba-4372-cf99-19427bf31df3"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/189155 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b46a7b750e184559a21e67a8854ca0f8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/21018 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be03ddf616f1489c8b77e3faba5a3103"}},"metadata":{}}]},{"cell_type":"code","source":["batch = data_collator([tokenized_datasets[\"train\"][i] for i in range(1, 3)])\n","batch.keys()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E75BhYIsGVJ9","executionInfo":{"status":"ok","timestamp":1702073795636,"user_tz":-180,"elapsed":336,"user":{"displayName":"Ekaterina Esina","userId":"08559422542032477941"}},"outputId":"a02f56b5-d2ff-40b4-e03f-8b7198f22b2c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['input_ids', 'attention_mask', 'labels', 'decoder_input_ids'])"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["import evaluate\n","import numpy as np\n","\n","metric = evaluate.load('sacrebleu')\n","\n","def compute_metrics(eval_preds):\n","    preds, labels = eval_preds\n","    # In case the model returns more than the prediction logits\n","    if isinstance(preds, tuple):\n","        preds = preds[0]\n","\n","    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n","\n","    # Replace -100s in the labels as we can't decode them\n","    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n","    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","\n","    # Some simple post-processing\n","    decoded_preds = [pred.strip() for pred in decoded_preds]\n","    decoded_labels = [[label.strip()] for label in decoded_labels]\n","\n","    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n","    return {\"bleu\": result[\"score\"]}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["202c9abf920a4b658cdbfcb1fddfd4e0","1a781ee9042c4b84b27fa5859bac03df","023618b106cf49d68871b6b0dfed3aeb","1a275270635b4ebdb7d2a21b46a52e6c","3670992f07bc412d871b62e1198db4f2","c61cdcf51c1d4d44855e165408e2030a","9525b31429f943efab110e587fd9ecac","cc3b81b039c64c709634cac6971ba379","b3b4ed6880d34ab7a96ce1d286465a0a","9ff0e724becc4867be35d31e43e4b0ee","5c997eac9cb44ba2a98f9b2e77832a02"]},"id":"j0ZRJ2ZDQ6u-","executionInfo":{"status":"ok","timestamp":1702073799372,"user_tz":-180,"elapsed":1784,"user":{"displayName":"Ekaterina Esina","userId":"08559422542032477941"}},"outputId":"c5a9b7a4-c5d1-4434-dd8a-6c4e329455f3"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading builder script:   0%|          | 0.00/8.15k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"202c9abf920a4b658cdbfcb1fddfd4e0"}},"metadata":{}}]},{"cell_type":"code","source":["from transformers import Seq2SeqTrainingArguments\n","\n","args = Seq2SeqTrainingArguments(\n","    f\"marian-finetuned-kde4-en-to-fr\",\n","    evaluation_strategy=\"no\",\n","    save_strategy=\"epoch\",\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=32,\n","    per_device_eval_batch_size=64,\n","    weight_decay=0.01,\n","    save_total_limit=3,\n","    num_train_epochs=3,\n","    predict_with_generate=True,\n","    fp16=True,\n","    push_to_hub=False,\n",")"],"metadata":{"id":"SY9X0vwvfKLh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import Seq2SeqTrainer\n","\n","trainer = Seq2SeqTrainer(\n","    model,\n","    args,\n","    train_dataset=tokenized_datasets[\"train\"],\n","    eval_dataset=tokenized_datasets[\"validation\"],\n","    data_collator=data_collator,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics,\n",")"],"metadata":{"id":"JKjR4WX4fsKn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer.evaluate(max_length=max_length)"],"metadata":{"id":"KZ-hayOvftEJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer.train()"],"metadata":{"id":"rKbB_6xifver"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer.evaluate(max_length=max_length)"],"metadata":{"id":"7MdpoR6ZfvbD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"XJCKl-o4fvYk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#####Custom training loop"],"metadata":{"id":"jaL54HVUhZms"}},{"cell_type":"code","source":["from datasets import load_dataset\n","\n","raw_dataset = load_dataset('kde4', lang1='en', lang2='fr')\n","split_datasets = raw_dataset['train'].train_test_split(train_size=0.9, seed=20)\n","split_datasets['validation'] = split_datasets.pop('test')"],"metadata":{"id":"8lxc2SWThs_O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["max_length = 128\n","\n","def preprocess_function(examples):\n","    inputs = [ex[\"en\"] for ex in examples[\"translation\"]]\n","    targets = [ex[\"fr\"] for ex in examples[\"translation\"]]\n","    model_inputs = tokenizer(inputs, text_target=targets,\n","                             max_length=max_length, truncation=True)\n","    return model_inputs\n","\n","tokenized_datasets = split_datasets.map(\n","    preprocess_function,\n","    batched=True,\n","    remove_columns=split_datasets[\"train\"].column_names,\n",")"],"metadata":{"id":"mMbLA1ZMh-dm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import DataLoader\n","\n","tokenized_datasets.set_format(\"torch\")\n","train_dataloader = DataLoader(\n","    tokenized_datasets[\"train\"],\n","    shuffle=True,\n","    collate_fn=data_collator,\n","    batch_size=8,\n",")\n","eval_dataloader = DataLoader(tokenized_datasets[\"validation\"],\n","                             collate_fn=data_collator, batch_size=8)"],"metadata":{"id":"lqvT-cwUh3rh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, AdamW\n","\n","model_checkpoint = \"Helsinki-NLP/opus-mt-en-fr\"\n","tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, return_tensors=\"pt\")\n","model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n","\n","# data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n","\n","optimizer = AdamW(model.parameters(), lr=2e-5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r1A4BrONht1B","executionInfo":{"status":"ok","timestamp":1702074716668,"user_tz":-180,"elapsed":4588,"user":{"displayName":"Ekaterina Esina","userId":"08559422542032477941"}},"outputId":"f8764ce6-3c93-44da-e1e2-29ddf58ffa62"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/models/marian/tokenization_marian.py:197: UserWarning: Recommended: pip install sacremoses.\n","  warnings.warn(\"Recommended: pip install sacremoses.\")\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]}]},{"cell_type":"code","source":["from accelerate import Accelerator\n","\n","accelerator = Accelerator()\n","model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n","    model, optimizer, train_dataloader, eval_dataloader)"],"metadata":{"id":"ezimNa-mhxUE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import get_scheduler\n","\n","num_train_epochs = 3\n","num_update_steps_per_epoch = len(train_dataloader)\n","num_training_steps = num_train_epochs * num_update_steps_per_epoch\n","\n","lr_scheduler = get_scheduler(\n","    \"linear\",\n","    optimizer=optimizer,\n","    num_warmup_steps=0,\n","    num_training_steps=num_training_steps,\n",")"],"metadata":{"id":"g9C93L03hH7J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def postprocess(predictions, labels):\n","    predictions = predictions.cpu().numpy()\n","    labels = labels.cpu().numpy()\n","\n","    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n","\n","    # Replace -100 in the labels as we can't decode them.\n","    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n","    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","\n","    # Some simple post-processing\n","    decoded_preds = [pred.strip() for pred in decoded_preds]\n","    decoded_labels = [[label.strip()] for label in decoded_labels]\n","    return decoded_preds, decoded_labels"],"metadata":{"id":"O8Z7R9kyiZdh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tqdm.auto import tqdm\n","import torch\n","\n","output_dir = \"/content/drive/MyDrive/Colab Notebooks/тексты/5_Transformers/trans\"\n","progress_bar = tqdm(range(num_training_steps))\n","\n","for epoch in range(num_train_epochs):\n","    # Training\n","    model.train()\n","    for batch in train_dataloader:\n","        outputs = model(**batch)\n","        loss = outputs.loss\n","        accelerator.backward(loss)\n","\n","        optimizer.step()\n","        lr_scheduler.step()\n","        optimizer.zero_grad()\n","        progress_bar.update(1)\n","\n","    # Evaluation\n","    model.eval()\n","    for batch in tqdm(eval_dataloader):\n","        with torch.no_grad():\n","            generated_tokens = accelerator.unwrap_model(model).generate(\n","                batch[\"input_ids\"],\n","                attention_mask=batch[\"attention_mask\"],\n","                max_length=128,\n","            )\n","        labels = batch[\"labels\"]\n","\n","        # Necessary to pad predictions and labels for being gathered\n","        generated_tokens = accelerator.pad_across_processes(\n","            generated_tokens, dim=1, pad_index=tokenizer.pad_token_id\n","        )\n","        labels = accelerator.pad_across_processes(labels, dim=1, pad_index=-100)\n","\n","        predictions_gathered = accelerator.gather(generated_tokens)\n","        labels_gathered = accelerator.gather(labels)\n","\n","        decoded_preds, decoded_labels = postprocess(predictions_gathered, labels_gathered)\n","        metric.add_batch(predictions=decoded_preds, references=decoded_labels)\n","\n","    results = metric.compute()\n","    print(f\"epoch {epoch}, BLEU score: {results['score']:.2f}\")\n","\n","    # Save and upload\n","    accelerator.wait_for_everyone()\n","    unwrapped_model = accelerator.unwrap_model(model)\n","    unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)\n","    if accelerator.is_main_process:\n","        tokenizer.save_pretrained(output_dir)\n","        # repo.push_to_hub(commit_message=f\"Training in progress epoch {epoch}\", blocking=False)"],"metadata":{"id":"D_KUx-6ciyiG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"otiSb_qmiydP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ch6KPNehkvXf"},"execution_count":null,"outputs":[]}]}